---
title: The Death of Problem-Solving Anticipation
date: 2025-11-30
draft: false
tags:
  - personal
  - ai
  - coding
  - featured
---
Clickbait Title: The Birth of AI Gambling.

We joke around a lot about programmers being awake at impossible times. Not sleeping for a night for a competition or a personal project is casually mentioned. Why is that? Sure sometimes you'll be fixing up-time or only have 24 hours in a CTF, but come on, we've all worked into the night when we could've just gone to bed and worked on it the next day. I find that remarkable.

In my puritan worldview, the main thing making people stay up beyond responsibility and [revenge procrastination](https://en.wikipedia.org/wiki/Bedtime_procrastination) is some sort of stimulating thing (keeping it vague on purpose). So what makes programming stimulating? In my opinion, it is **the chase**. Chasing a solution to a problem, chasing a finalised system, chasing the qualitative answer to a question.

Beyond self-diagnosing, I can explain my behaviour of focusing so hard on programming I forget to eat, sleep or talk to people through nothing less than just a deeply seated need. Programming is stimulating, and it's not because we have fancy LSPs lighting up the screen. The deeper I am in abstract material, the further I have stepped down the mental call-stack, the more impossible does it feel to put all of this aside to tuck in for some sweet dreams. (I have had sleepless nights trying to go to bed when I'm in too deep)

So, we have this "feature" of programming where we can build up incredible unresolved tension. Is it good? Probably not healthy in the long run. But I would not discount just how much you learn by being able to dedicate this number of incredible hours into a complex topic. In my eyes, the focus vs. payoff graph tends to follow something like the curve $x^{1.5}$, the longer you stay in it, the better.

Now if you are working three jobs and have a family to care for and real responsibilities then being caught up in programming might actually be detrimental. I will also not deny that there are probably some very obsessive programmers who could do some other healthy things as well. But what I will outright reject the idea that programming should *not* be this way.

Well, I am not many of those. I've got time which I'm mainly wasting doing things which have a faster engagement rate (because they were engineered to do so). The blunt force of how interesting problem-solving for hours is a main driver of healthy focus in my life.

### Copy-paste
I hate a lot of programmer-related jokes, mainly because they're popularised not by programmers, but by people who have been thinking into getting into programming. Luckily one of them has been dying recently: "Ohhh all programmers just copy from StackOverflow".

Copying code from other places has been the main way programmers used to turn off their brain whilst still getting lines into the textfile. The more specific the code is to your problem (i.e. the more boring your problem is), the more you can even count on it just doing the thing for you perfectly. Maybe it throws an error or the input format is different. That's good, it means you at least need to turn on your brain to do plumbing.

Well, the joke is dying for a bad reason. People just copy from AI now. Or you know, give the AI access to their entire project and just let it do it even that thing. God forbid looking at the code you're copy-pasting. Oh and forget about needing to adjust the code to fit your project, it'll just perfectly slot in there. Truly this "coding" is a "vibe".

There's tons of problems with this (these models are still very stupid if the code is not javascript or python, maintainability is non-existent, your specification is probably not detailed enough, you wont be able to work with other people), but the one I want to discuss is the lack of required focus.

There's a meme going around that implies that using LLMs for coding is basically the same as gambling. This is obvious in-part for shock appeal, but what I do think is true is that using LLMs is basically a [Skinner box](https://en.wikipedia.org/wiki/Operant_conditioning_chamber). You repeatedly press the generate button (giving the company money with each API call) and sometimes you get a reward (code compiles).

I am not going to comment on gambling psychology, but... I do think that programming with LLMs is so popular because getting code that compiles after it didn't is very rewarding. If you hunker down and solve it yourself, you will spend more time. Using an LLM (when/if it can solve it) is fast immediate reward without putting in effort.

So, on the one hand I see programming as one of the last places for me to hide from the attention economy and on the other you have incredibly well-funded efforts to apply the same reward algorithm as a mobile game.

Speaking of pay to win mobile games, as we are moving towards the new trend of "agentic" agents, the LLM API builder industry has stolen yet another innovation: The "auto" button. It is a button where depending on the game, it will completely play itself, or at least farm some resources. You can either leave it running in the background or just stare at the pretty colours. So if we follow this principle, next they're going to add ads and then constant limited time offers? They've already added sexualised anime women.


### Knowledge through Failure
I've described my knowledge in IT to non-programmers as follows: "I've just made every single mistake already before". It is true. A lot of IT knowledge beyond understanding abstract concepts is just having spent more time stepping into dirt than others. It's the stupidest brute-force algorithm you can have, but knowledge is so illogical and fractal sometimes.

So what do you get when you have a sleepless night trying to rescue your Linux installation? A lot of mistakes, if you're paying attention. You are basically a working scientist, formulating hypotheses, testing them, ad finitum. I cannot overstate how *this* is the main process that will build knowledge, not the part where you have the solution and run it.

Now, sometimes you will just need something to be done, because you know the point right now is not to learn Linux Kernel modules, it's to get a python environment running. But if you're doing this for yourself, at home, do you really **know** what you want? The problem with driving through a forest in a car is that you don't stumble over any interesting branches.

Now, I know that you can use LLMs for knowledge-building. They are very good at finding keywords for a topic for example. They also do not yet suffer the same SEO manipulation as Google and others. But they are certainly bad for finding a thing you never knew you wanted. If you vibecode your bugs away, you will never find yourself gdb stepping through the stdlib only to learn of a new opcode.

### Patience
The most popular claims on attention-span I find very dubious. But what I have noticed for myself is that nowadays I find myself looking at problems and being aghast that they take 2 hours to solve, even at my best effort. I think there is some kind of expectation that if you're just *smart enough* (smart in general, not even in this specific topic), everything should be easy. Maybe the space of possible solutions is very large, but if you grasp the correct path through it, it is only a few steps. This is mostly wrong in my experience.

A lot of things will just take a few hours if you've never seen them before. This is normal. You are not dumb or incompetent, you just don't have 10'000 hours spent on it yet. Spend the hours, there is no shortcut.

And if you get an interesting enough problem, you can spend many hours in a single day. Just remember to eat something.
